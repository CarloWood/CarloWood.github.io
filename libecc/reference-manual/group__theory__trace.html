<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html LANG="en_US">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<meta name="Author" content="Carlo Wood">
<meta name="description" content="Elliptic Curve Cryptography C++ Library">
<meta name="keywords" content="libecc, fast, elliptic curves, cryptography, fixed key size, speed, object orientation, OO, C++">
<title>libecc: Elliptic Curve Cryptography C++ Library - Reference Manual</title>
<link href="doxygen.css" rel="stylesheet" type="text/css">
<script src="../scripts/detect_browser.js"></script>
<script>need_style_doxygen=1</script>
<script src="../scripts/load_style_sheets.js"></script>
</head>
<body>
<div class="normal">
<center>
<a class="qindex" href="../index.html">Main Page</a> &nbsp;
<a class="qindex" href="index.html">Reference Manual</a> &nbsp;
<a class="qindex" href="annotated.html">Compound List</a> &nbsp;
<a class="qindex" href="files.html">File List</a> &nbsp;
</center>
<hr size=1 noshade>
<!-- Generated by Doxygen 1.8.18 -->
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Theory: The trace of a field element</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock">You probably already heard of the <a href="http://www.mathreference.com/la-sim,trace.html">trace of a matrix</a>.&#160; It is defined as the sum of the diagonal elements of a square matrix.&#160; What is so special about that?&#160; Well, as explained by that link, the trace is basis invariant.&#160; Let <span class="formula">L : K</span> be a <a class="el" href="group__theory__polynomial.html#fieldextension">finite field extension</a>, like <span class="formula"><img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span> is a field extension of <span class="formula"><img class="formulaInl" alt="$\mathbb{Z}$" src="form_1036_58.png"/><sub>2</sub></span>.&#160; Given some linear transformation <span class="formula">A: L <img class="formulaInl" alt="$\rightarrow$" src="form_1036_67.png"/> L</span> you can write that linear transformation in the form of a matrix equation (because it is linear) <img class="formulaInl" alt="$A_yx = yx$" src="form_1036_277.png" width="54" height="14"/> after chosing some basis for <span class="formula">L</span> that associates <span class="formula">L</span> with a vector space.&#160; This equation is linear in <span class="formula">x</span> because <span class="formula">y</span> is fixed.&#160; We already saw discussed one such basis for our field <span class="formula"><img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span>, <a class="el" href="group__theory__aspace.html#basis">elsewhere</a>: <span class="formula">(1, t, t<sup>2</sup>, t<sup>3</sup>, ..., t<sup>m-1</sup>)</span>.Lets work out a simple example using this polynomial basis.&#160; Let <span class="formula">m = 4</span>, using reduction polynomial <span class="formula">t<sup>4</sup> + t + 1</span>.&#160; Let <span class="formula">y = t</span>, some element of our field <span class="formulaF"> <img class="formulaInl" alt="$\mathbb{F}$" src="form_1036_6.png"/><sub>2<sup>4</sup></sub></span>.&#160; The linear transformation that sends <span class="formula">x <img class="formulaInl" alt="$\rightarrow$" src="form_1036_67.png"/> yx</span> is then given by, <span class="formula">A<sub>t</sub>x = tx</span>.&#160; The trace of the matrix should be independent of the chosen basis, so that we might as well talk about "the trace of the linear transformation", or even about "the trace of y", for <span class="formula">y</span> uniquely determines this transformation.&#160; Multiplying with <span class="formula">t</span> means that this transformation sends <span class="formula">1</span> to <span class="formula">t</span>, <span class="formula">t</span> to <span class="formula">t<sup>2</sup></span>, ... and <span class="formula">t<sup>m-2</sup></span> to <span class="formula">t<sup>m-1</sup></span>.&#160; Only the transformation of the last member of our polynomial basis is a little different: <span class="formula">t<sup>m-1</sup> <img class="formulaInl" alt="$\rightarrow$" src="form_1036_67.png"/> tt<sup>m-1</sup> = t<sup>k</sup> + 1</span>.&#160; Writing out the matrix for the given example gives therefore,<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \\ x_3 \end{pmatrix} = t \begin{pmatrix} x_0 \\ x_1 \\ x_2 \\ x_3 \end{pmatrix} \]" src="form_1036_278.png" width="173" height="61"/>
</p>
where <span class="formula">x<sub>i</sub></span> is the coefficient corresponding to the basis element <span class="formula">t<sup>i</sup></span>.We find that in this case the trace is <span class="formula">Tr(A<sub>t</sub>) = Tr(t) = 0</span> (the sum of the diagonal elements of the matrix).&#160; Please note that <span class="formula">Tr(y)</span> is an element of <span class="formula">K</span> (being <img class="formulaInl" alt="$\mathbb{Z}$" src="form_1036_58.png"/><sub>2</sub> in our case): adding the diagonal elements (which are all element of <span class="formula">K</span>) is still done modulo 2!The more general matrix (for arbitrary <span class="formula">m</span> for which there exists an irreducible trinomial <span class="formula">t<sup>m</sup> + t<sup>k</sup> + 1</span> that is used as reduction polynomial) leads to the matrix<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; \cdots &amp; &amp; &amp; &amp; \cdots &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; &amp; &amp; &amp; &amp; &amp; &amp; &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; &amp; &amp; &amp; &amp; &amp; &amp; 0 \\ 0 &amp; &amp; 1 &amp; 0 &amp; &amp; &amp; &amp; &amp; &amp; \vdots \\ \vdots &amp; &amp; &amp; \ddots &amp; \ddots &amp; &amp; &amp; &amp; &amp; 0 \\ &amp; &amp; &amp; &amp; 1 &amp; 0 &amp; &amp; &amp; &amp; 1 \\ &amp; &amp; &amp; &amp; &amp; 1 &amp; 0 &amp; &amp; &amp; 0 \\ \vdots &amp; &amp; &amp; &amp; &amp; &amp; \ddots &amp; \ddots &amp; &amp; \vdots \\ 0 &amp; &amp; &amp; &amp; &amp; &amp; &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; \cdots &amp; &amp; &amp; &amp; &amp; \cdots &amp; 0 &amp; 1 &amp; 0 \end{pmatrix} \]" src="form_1036_279.png" width="240" height="174"/>
</p>
where the lower <span class="formula">1</span> in the right-most column appears in the k-th row, and hence we can immediately see that<p class="formulaDsp">
<img class="formulaDsp" alt="\[ Tr(t) = \begin{cases} 0 &amp; k \neq m - 1 \\ 1 &amp; k = m - 1 \end{cases} \]" src="form_1036_280.png" width="130" height="39"/>
</p>
Since libecc forbids values of <span class="formula">k &gt; m/2</span>, we can safely assume that in our case the trace of <span class="formula">t</span> is always 0.Lets investigate that this trace is indeed independent of the chosen basis by applying a basis transformation.&#160; The only possible basis transformation happens to be applying <a class="el" href="group__theory__frobenius.html">Frobenius</a> a number of times.&#160; Lets investigate applying Frobenius once.The <a class="el" href="group__theory__frobenius.html">Frobenius map</a> sends <span class="formula">1 <img class="formulaInl" alt="$\rightarrow$" src="form_1036_67.png"/> 1</span>, <span class="formula">t <img class="formulaInl" alt="$\rightarrow$" src="form_1036_67.png"/> t<sup>2</sup></span>, <span class="formula">t<sup>2</sup> <img class="formulaInl" alt="$\rightarrow$" src="form_1036_67.png"/> t<sup>4</sup> = t + 1</span> and <span class="formula">t<sup>3</sup> <img class="formulaInl" alt="$\rightarrow$" src="form_1036_67.png"/> t<sup>6</sup> = t<sup>3</sup> + t<sup>2</sup></span>.&#160; From which follows that the corresponding matrix is<p class="formulaDsp">
<img class="formulaDsp" alt="\[ Frob(x) = \begin{pmatrix} 1 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \\ x_3 \end{pmatrix} = \begin{pmatrix} z_0 \\ z_1 \\ z_2 \\ z_3 \end{pmatrix} \]" src="form_1036_281.png" width="229" height="61"/>
</p>
the inverse of which is<p class="formulaDsp">
<img class="formulaDsp" alt="\[ Frob^{-1}(z) = \begin{pmatrix} 1 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix} \begin{pmatrix} z_0 \\ z_1 \\ z_2 \\ z_3 \end{pmatrix} = \begin{pmatrix} x_0 \\ x_1 \\ x_2 \\ x_3 \end{pmatrix} \]" src="form_1036_282.png" width="241" height="61"/>
</p>
Applying <a class="el" href="group__theory__frobenius.html">Frobenius</a> to the equation <span class="formula">A<sub>t</sub>x = tx</span> gives <span class="formula">Frob(A<sub>t</sub>x) = Frob(tx) = t Frob(x)</span>, where the last equality holds because that <span class="formula">t</span> is a constant.&#160; Furthermore, <span class="formula">Frob(A<sub>t</sub>x) = Frob(A<sub>t</sub> Frob<sup>-1</sup>(Frob(x))) = Frob(A<sub>t</sub> Frob<sup>-1</sup>(z))</span>, which brings us to the matrix equation<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \begin{pmatrix} 1 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix} \begin{pmatrix} 0 &amp; 0 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ \end{pmatrix} \begin{pmatrix} 1 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix} \begin{pmatrix} z_0 \\ z_1 \\ z_2 \\ z_3 \end{pmatrix} = t \begin{pmatrix} z_0 \\ z_1 \\ z_2 \\ z_3 \end{pmatrix} \]" src="form_1036_283.png" width="341" height="61"/>
</p>
Working out the matrix multiplication we get<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \begin{pmatrix} 1 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 0 &amp; 1 \end{pmatrix} \begin{pmatrix} z_0 \\ z_1 \\ z_2 \\ z_3 \end{pmatrix} = t \begin{pmatrix} z_0 \\ z_1 \\ z_2 \\ z_3 \end{pmatrix} \]" src="form_1036_284.png" width="169" height="61"/>
</p>
where the <span class="formula">z<sub>i</sub></span> are the coefficients relative to the basis <span class="formula">(1, t<sup>2</sup>, t + 1, t<sup>3</sup> + t<sup>2</sup>)</span>.&#160; And indeed, still we have <span class="formula">Tr(t) = 1 + 1 + 1 + 1 = 0</span>.More in general, any change of basis can be represented with some non-singular matrix (which means that its determinant is non-zero and thus that it has an inverse).&#160; Let the matrix <span class="formula">B</span> represent a change of basis, then the matrix <span class="formula">A<sub>t</sub></span> will change into <span class="formula">BA<sub>t</sub>/B</span>, preserving the value of the determinant (see formula 18 on <a href="http://mathworld.wolfram.com/Determinant.html">this page</a>) and the value of the trace (see formula 7 on <a href="http://mathworld.wolfram.com/MatrixTrace.html">this page</a>).The following is not a proof in any way, but it gives things a bit a place, and therefore making it easier to understand more mathematical texts that actually derive and prove things, I hope.&#160;Consider the linear equation (using some basis)<p class="formulaDsp">
<img class="formulaDsp" alt="\[ (A_i - \lambda_iI)x_i = 0 \]" src="form_1036_285.png" width="90" height="14"/>
</p>
Then <span class="formula"><img class="formulaInl" alt="$\lambda$" src="form_1036_286.png" width="8" height="10"/><sub>i</sub></span> are the <a href="http://www.mathreference.com/la-det,eigen.html"><em>eigen values</em></a> of <span class="formula">A</span> and <span class="formula">x<sub>i</sub></span> are the corresponding <a href="http://www.mathreference.com/la-det,eigen.html"><em>eigen vectors</em></a>.&#160; Note that for a fixed <span class="formula"><img class="formulaInl" alt="$\lambda$" src="form_1036_286.png" width="8" height="10"/><sub>i</sub></span> the above represents the linear transformation (<span class="formula">A<sub>i</sub>x<sub>i</sub> = <img class="formulaInl" alt="$\lambda$" src="form_1036_286.png" width="8" height="10"/><sub>i</sub>x<sub>i</sub></span>).&#160;For the story about <em>eigen values</em> and corresponding <em>eigen vectors</em>, <span class="formula"><img class="formulaInl" alt="$\lambda$" src="form_1036_286.png" width="8" height="10"/><sub>i</sub></span> has to be an element of the base field <span class="formula">K</span> (<span class="formulaF"> <img class="formulaInl" alt="$\mathbb{F}$" src="form_1036_6.png"/><sub>2</sub></span>), so we really only have one non-trivial eigen value: <span class="formula">1</span>.&#160; Plugging that value into the equation turns <span class="formula">A</span> into the identity matrix and trivally all of the vector space into the corresponding <em>eigen space</em> (that is, every value of <span class="formula">x</span> is an eigen vector of the identity matrix with scaling factor <span class="formula">1</span>; what else is new).&#160; But we can also consider values for <span class="formula">y = <img class="formulaInl" alt="$\lambda$" src="form_1036_286.png" width="8" height="10"/><sub>i</sub></span> that are element of <span class="formula">L</span>, in that case we simply get the equation <span class="formula">A<sub>y</sub>x = yx</span> which holds per definition for any value <span class="formula">x <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/> L</span>.&#160; Nevertheless, we can still call <span class="formula">y</span> <em>eigen value</em> and <a href="http://www.mathreference.com/la-sim,trace.html">related theorems</a> still hold, like that the trace of the matrix is the sum of all its eigen values (now elements of <span class="formula">L</span>), and the norm of the matrix (its determinant) is the product of all the eigen values.&#160; Below we assume that the eigen values <span class="formula">y <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/> L</span> and you can forget about the concept of eigen vectors: the equations are trivially true for any <span class="formula">x</span>.&#160; This paragraph was just added to take away possible confusion about that.Obviously <span class="formula">(A<sub>y</sub> - yI)</span> can't have an inverse when <span class="formula">(A<sub>y</sub> - yI)x = 0</span> for every <span class="formula">x <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/> <img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span>.&#160; The matrix will be singular therefore, its determinant will be zero and we have <span class="formula"><span class="vbars">A<sub>y</sub> - yI</span> = 0</span>.&#160; The determinant is a polynomial in <span class="formula">y</span> of degree <span class="formula">m</span> and the equation is called the characteristic equation (or polynomial) of <span class="formula">A<sub>y</sub></span>; the roots are the eigen values of the matrix.&#160;If we choose <span class="formula">y = t</span> and consider<p class="formulaDsp">
<img class="formulaDsp" alt="\[ A_tx = tx \]" src="form_1036_287.png" width="49" height="13"/>
</p>
or<p class="formulaDsp">
<img class="formulaDsp" alt="\[ (A_t - tI)x = 0 \]" src="form_1036_288.png" width="79" height="14"/>
</p>
then the equation <span class="formula"><span class="vbars">A<sub>t</sub> - tI</span> = 0</span> must be the minimal polynomial of <span class="formula">t</span> (that is, a monomial of degree m): it is the reduction polynomial!&#160; The corresponding <span class="formula">A<sub>t</sub></span> will have eigen values that are precisely the roots of the reduction polynomial.&#160; What are those roots?We already have one root (per definition): <span class="formula">t</span> itself.&#160; It is near impossible to write out <span class="formula">t</span> in its complex form, that would result in <a href="http://planetmath.org/encyclopedia/QuarticFormula.html">huge formulas</a> if at all possible to find, but we don't have to do that.&#160; We can express the other roots easily in <span class="formula">t</span> by repeatedly applying <a class="el" href="group__theory__frobenius.html">Frobenius</a>.For example, let the reduction polynomial be <span class="formula">t<sup>4</sup> + t + 1 = 0</span>.&#160; Then by replacing each <span class="formula">t</span> with its square, the equation still holds: <span class="formula">(t<sup>2</sup>)<sup>4</sup> + t<sup>2</sup> + 1 = t<sup>4</sup>t<sup>4</sup> + t<sup>2</sup> + 1 = (t + 1)<sup>2</sup> + t<sup>2</sup> + 1 = t<sup>2</sup> + 1 + t<sup>2</sup> + 1 = 0</span>.&#160; And doing that again, it still holds: <span class="formula">(t<sup>4</sup>)<sup>4</sup> + t<sup>4</sup> + 1 = (t + 1)<sup>4</sup> + t<sup>4</sup> + 1 = 0</span>, and so on.&#160; After all, the <a class="el" href="group__theory__frobenius.html">Frobenius map</a> is an automorphism.&#160; <a class="anchor" id="differentvalues"></a>If <span class="formula">t</span> is a generator of the field and its order is <span class="formula">n = 2<sup>m</sup> - 1</span>, hence <span class="formula">n</span> is the smallest positive integer such that <span class="formula">t<sup>n</sup> = 1</span>, then applying Frobenius <span class="formula">m - 1</span> times will lead necessarily to <span class="formula">m</span> different values.&#160; The roots of the reduction polynomial are therefore given by the set <span class="formula">(t, t<sup>2</sup>, t<sup>2<sup>2</sup></sup>, ..., t<sup>2<sup>m-1</sup></sup>)</span> and they represent the eigen values of the matrix <span class="formula">A<sub>t</sub></span> in the linear transformation <span class="formula">A<sub>t</sub>x = tx</span>, independent of the basis.&#160; If <span class="formula">t</span> is not a generator of the field, which is possible when <span class="formula">m</span> is non-prime, it might happen that the same eigen value is shared by more than one eigen vector, but in that case we have to add the same eigen value multiple times.&#160; Therefore, the trace of <span class="formula">t</span> is given by the sum of this set and the <span class="formula">det<span class="vbars">A<sub>t</sub></span></span> is given by the product of this set.The same story holds for an arbitrary value of <span class="formula">y</span> (not zero), and we find<p class="formulaDsp">
<img class="formulaDsp" alt="\[ Tr(y) = \sum_{i=0}^{m-1}{y^{2^i}} \]" src="form_1036_289.png" width="88" height="38"/>
</p>
Also note that <span class="formula"><img class="formulaInl" alt="$det \vert A_y \vert = \prod_{i=0}^{m-1}{y^{2^i}} = y^{2^m-1} = 1$" src="form_1036_290.png" width="180" height="18"/></span> which makes us jump of joy because it means that every non-zero <span class="formula">y</span> has an inverse, as should be the case for field elements!<hr  />
The roots of the reduction polynomial are not always linear independent and we can't use them as a basis, but it can be proven that there will always exist some element <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/> such that <span class="formula">( <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/>, <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2</sup>, <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2<sup>2</sup></sup>, ..., <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2<sup>m-1</sup></sup>)</span> is linear independent.&#160; Such a basis is called a <a href="http://www.certicom.com/index.php?action=ecc_tutorial,math9"><em>normal</em> basis</a>.&#160;As an example, let the reduction polynomial again be <span class="formula">t<sup>4</sup> + t + 1</span>.&#160; The set <span class="formula">(t, t<sup>2</sup>, t<sup>4</sup>, t<sup>8</sup>) = (t, t<sup>2</sup>, t + 1, t<sup>2</sup> + 1)</span> is clearly not linear independent.&#160; However, we can chose <span class="formula"><img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/> = t<sup>3</sup></span> and find a normal basis <span class="formula">(t<sup>3</sup>, t<sup>3</sup> + t<sup>2</sup>, t<sup>3</sup> + t<sup>2</sup> + t + 1, t<sup>3</sup> + t)</span>.&#160; If next we want to find the matrix that corresponds with <span class="formula">A<sub>t</sub>x = tx</span> (multiplication with <span class="formula">t</span>) then we have to first figure out how the basis elements are converted.&#160;<span class="formula">t(t<sup>3</sup>) = t<sup>4</sup> = t + 1 = (t<sup>3</sup> + t<sup>2</sup>) + (t<sup>3</sup> + t<sup>2</sup> + t + 1)</span>.<br  />
 <span class="formula">t(t<sup>3</sup> + t<sup>2</sup>) = t<sup>3</sup> + t + 1 = (t<sup>3</sup>) + (t<sup>3</sup> + t<sup>2</sup>) + (t<sup>3</sup> + t<sup>2</sup> + t + 1)</span>.<br  />
 <span class="formula">t(t<sup>3</sup> + t<sup>2</sup> + t + 1) = t<sup>3</sup> + t<sup>2</sup> + 1 = (t<sup>3</sup>) + (t<sup>3</sup> + t<sup>2</sup> + t + 1) + (t<sup>3</sup> + t)</span>.<br  />
 <span class="formula">t(t<sup>3</sup> + t) = t<sup>2</sup> + t + 1 = (t<sup>3</sup>) + (t<sup>3</sup> + t<sup>2</sup> + t + 1)</span>.And thus we have<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \begin{pmatrix} 0 &amp; 1 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 0 &amp; 0 \\ 1 &amp; 1 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 1 &amp; 0 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \\ x_3 \end{pmatrix} = t \begin{pmatrix} x_0 \\ x_1 \\ x_2 \\ x_3 \end{pmatrix} \]" src="form_1036_291.png" width="173" height="61"/>
</p>
Note that again <span class="formula">Tr(t) = 0</span>, as it should be.&#160; Lets have a look at an element whose trace will <em>not</em> be 0 for change, like <span class="formula">t<sup>3</sup></span>.&#160; Using the above formula for the trace we can immediately calculate it.<p class="formulaDsp">
<img class="formulaDsp" alt="\[ Tr(t^3) = t^3 + t^6 + t^9 + t^{12} = t^3 + (t^3 + t^2) + (t^3 + t^2 + t + 1) + (t^3 + t) = 1 \]" src="form_1036_292.png" width="409" height="16"/>
</p>
Note that this is exactly the sum of the normal basis that we used above.Lets do one more check with a matrix, using this same basis.&#160; The basis elements are converted as follows:<span class="formula">t<sup>3</sup>(t<sup>3</sup>) = (t<sup>3</sup> + t<sup>2</sup>)</span>.<br  />
 <span class="formula">t<sup>3</sup>(t<sup>3</sup> + t<sup>2</sup>) = (t<sup>3</sup> + t)</span>.<br  />
 <span class="formula">t<sup>3</sup>(t<sup>3</sup> + t<sup>2</sup> + t + 1) = 1 = (t<sup>3</sup>) + (t<sup>3</sup> + t<sup>2</sup>) + (t<sup>3</sup> + t<sup>2</sup> + t + 1) + (t<sup>3</sup> + t)</span>.<br  />
 <span class="formula">t<sup>3</sup>(t<sup>3</sup> + t) = (t<sup>3</sup> + t<sup>2</sup> + t + 1)</span>.And thus we have<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \begin{pmatrix} 0 &amp; 0 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 1 &amp; 0 \end{pmatrix} \begin{pmatrix} x_0 \\ x_1 \\ x_2 \\ x_3 \end{pmatrix} = t^3 \begin{pmatrix} x_0 \\ x_1 \\ x_2 \\ x_3 \end{pmatrix} \]" src="form_1036_293.png" width="179" height="61"/>
</p>
and as expected, the trace of this matrix is 1.We can make an interesting observation here.&#160; A vector relative to a normal basis <span class="formula">( <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/>, <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2</sup>, <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2<sup>2</sup></sup>, ..., <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2<sup>m-1</sup></sup>)</span> allows us to denote every single element of the field of course, otherwise it wasn't a basis.&#160; The zero is always given by the vector <span class="formula">(0, 0, 0, ..., 0)</span>, and thus it is impossible that the vector <span class="formula">(1, 1, 1, ... 1)</span>, which corresponds to adding all elements of the normal basis, would be zero as well.&#160; Moreover, adding all elements of a normal basis means adding all the roots of <img class="formulaInl" alt="$\vert A_\beta - \beta I \vert = 0$" src="form_1036_294.png" width="75" height="14"/>, it is equal to the trace of <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/>, and a trace is element of the base field and can therefore only be equal to 0 or 1 in our case!&#160; Hence, in order for <span class="formula">( <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/>, <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2</sup>, <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2<sup>2</sup></sup>, ..., <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2<sup>m-1</sup></sup>)</span> to be a normal basis we <em>must</em> have <span class="formula">0 <img class="formulaInl" alt="$\neq$" src="form_1036_12.png"/> Tr( <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/>) = 1</span>&#160;!Now consider the following magic.&#160; When <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/>, in combination with Frobenius, can be used to form a normal basis, then so can <span class="formula"><img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2</sup></span> because if you replace <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/> with <span class="formula"><img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2</sup></span> in the basis you simply get <span class="formula">( <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2</sup>, <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2<sup>2</sup></sup>, ..., <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2<sup>m-1</sup></sup>, <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/>)</span>.&#160; Therefore, it must be that <span class="formula">Tr( <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2</sup>) = 1</span> too.&#160; The inverse is also true, if <span class="formula"><img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/><sup>2</sup></span> can be used to generate a normal basis then so can <img class="formulaInl" alt="$\beta$" src="form_1036_9.png"/>.&#160; Hence, we can conclude that for any arbitrary element <span class="formula">y</span><p class="formulaDsp">
<img class="formulaDsp" alt="\[ Tr(y) = Tr(Frob(y)) \]" src="form_1036_295.png" width="115" height="14"/>
</p>
This result is not too weird, considering that Frobenius is an automorphism that basically just changes the basis - and as we saw before, the trace is not dependent on the basis.In other words, <span class="formula">Tr(y - Frob(y)) = Tr(y) - Tr(Frob(y)) = 0</span>.&#160; And therefore we can conclude that the equation <span class="formula">x = y + y<sup>2</sup></span> can only have solutions when <span class="formula">Tr(x) = 0</span>&#160;! Note that <span class="formula">Frob(y) = y<sup>2</sup></span> and that, since we are working with characteristic 2, <span class="formula">y + y<sup>2</sup> = y - y<sup>2</sup></span>.And this is the result I needed to prove <a class="el" href="group__theory__aspace.html#hypothesis1">Hypothesis 1</a>.<a class="anchor" id="theorem5"></a><b>THEOREM 5</b><div class="theorem"> Let <span class="formula">x <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/> <span class="formula"><img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span></span>.&#160; Then <span class="formula">Tr(x) = 0</span> <a href="http://planetmath.org/encyclopedia/Biconditional.html">iff</a> there exists a <span class="formula">y <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/> <span class="formula"><img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span></span> such that <span class="formula">x = y + y<sup>2</sup></span>.</div><b>PROOF</b>There is another, easy way to prove theorem 5.&#160; Suppose there is a solution to the equation <span class="formula">x = y + y<sup>2</sup></span>, so that for a given <span class="formula">x</span> and <span class="formula">y</span> the equation is true.&#160; Then applying Frobenius to both sides (squaring both sides) results again in in an equation that is true of course.&#160; We can repeat squaring both sides precisely <span class="formula">m - 1</span> times at which point the term <span class="formula">y<sup>2</sup></span> will turn into <span class="formula">y</span> because <span class="formula">y<sup>2<sup>m</sup></sup> = y</span>.&#160; If we subsequently add up all those equations we get immedeate proof that the trace of <span class="formula">x</span> is <span class="formula">0</span>.<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \] \begin{eqnarray*} x &amp;=&amp; y + y^2 \\ x^2 &amp;=&amp; y^2 + y^4 \\ x^4 &amp;=&amp; y^4 + y^8 \\ \vdots \\ x^{2^{m-2}} &amp;=&amp; y^{2^{m-2}} + y^{2^{m-1}} \\ x^{2^{m-1}} &amp;=&amp; y^{2^{m-1}} + y \end{eqnarray*} \[ \]" src="form_1036_296.png" width="143" height="118"/>
</p>
where the sum of all left-hand-sides is precisely the trace of <span class="formula">x</span> and the sum of all right-hand-sides is zero!<hr  />
Weew, you have no idea how glad I am that I finally got to this point without using sophisticated mathematics!&#160; I worked five days on the above.&#160; Hopefully I reached my goal and you are now reasonably comfortable with Frobenius and traces.&#160; Just for the kicks (and so you appreciate my efforts a bit more), here is the "sophisticated" derivation:Let <span class="formula">G</span> be the <a href="http://www.mathreference.com/fld-gal,gg.html">Galois group</a> of the Galois extension <span class="formula">L/K</span>, then <img class="formulaInl" alt="$H^1(G,L) = H^1(G,L^*) = 0$" src="form_1036_297.png" width="146" height="15"/> (<a href="http://en.wikipedia.org/wiki/Hilbert&#39;s_Theorem_90">Hilbert's theorem 90</a>).&#160; Therefore, if <span class="formula">G</span> is cyclic with generator <span class="formula">g</span>, this is the same as <span class="formula">Norm(x) = 1 <img class="formulaInl" alt="$\iff$" src="form_1036_298.png" width="24" height="9"/> x = y/g(y)</span>.&#160; And <span class="formula">Tr(x) = 0 <img class="formulaInl" alt="$\iff$" src="form_1036_298.png" width="24" height="9"/> x = y - g(y)</span>.Also <em>trace</em> (of field elements) is usually <a href="http://planetmath.org/encyclopedia/Trace2.html">explained with Galois theory</a>.&#160; Maybe I'll add a chapter about Galois Theory later to this project.<hr  />
A week after I wrote the above, I found emperically an extremely fast way to find the trace of an element of <img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/>. I showed this method on an IRC channel on 10 December 2004 and posted it to the sci.math news group on 11 December 2004. I managed to find a prove for it on 18 December 2004 (see below). Unfortunately, then I found a (yet unpublished) article on the net that proved the same thing (theorem 7 of <a href="http://www.math.uwaterloo.ca/~oahmadid/tri-pent-trace.pdf">On the Number of Trace-One Elements in Polynomial Bases for F<sub>2<sup>n</sup></sub></a>).Although we found this independently, and although the other article will probably not be published before 2005, I suppose I can't publish it myself anymore; too bad.<a class="anchor" id="theorem6"></a></p><h3>THEOREM 6</h3>
<div class="theorem">Let <span class="formula">t<sup>j</sup> <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/> <img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span> with reduction polynomial <span class="formula">t<sup>m</sup> + t<sup>k<sub>0</sub></sup> + t<sup>k<sub>1</sub></sup> + <img class="formulaInl" alt="$\cdots$" src="form_1036_88.png"/> + t<sup>k<sub>n</sub></sup> + 1</span>, where each <span class="formula">k<sub>i</sub> &lt; m / 2</span>.&#160; Then the trace of <span class="formula">t<sup>j</sup></span> is 1 iff j is odd and there exists an <span class="formula">i</span> such that <span class="formula">j = m - k<sub>i</sub></span>, or when j = 0 and m is odd.</div>Please give me credit if you use it anywhere.<h3>PROOF</h3>
We start this proof with a repetion of the theory of eigenvalues and the trace, but slightly more rigorous because we need that to understand how the eigenvalues of a power of <span class="formula">t</span> relates to the eigenvalues of <span class="formula">t</span>.Let <span class="formula"><img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span> be the degree <span class="formula">m</span> extension field of <span class="formulaF"> <img class="formulaInl" alt="$\mathbb{F}$" src="form_1036_6.png"/><sub>2</sub></span>. Then <span class="formula"><img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/> =</span><span class="formulaF"> <img class="formulaInl" alt="$\mathbb{F}$" src="form_1036_6.png"/><sub>2</sub>[t]/(r(t))</span> where <span class="formula">r(t)</span> is an irreducible polynomial of degree <span class="formula">m</span> over <span class="formulaF"> <img class="formulaInl" alt="$\mathbb{F}$" src="form_1036_6.png"/><sub>2</sub></span>. The element <span class="formula"><img class="formulaInl" alt="$\alpha$" src="form_1036_7.png"/> = t</span> is a root of <span class="formula">r(t)</span> in <span class="formula"><img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span>, and <span class="formula">{ 1, <img class="formulaInl" alt="$\alpha$" src="form_1036_7.png"/>, <img class="formulaInl" alt="$\alpha$" src="form_1036_7.png"/><sup>2</sup>, ..., <img class="formulaInl" alt="$\alpha$" src="form_1036_7.png"/><sup>m-1</sup> }</span> is a basis for <span class="formula"><img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span> over <span class="formulaF"> <img class="formulaInl" alt="$\mathbb{F}$" src="form_1036_6.png"/><sub>2</sub></span>, called the polynomial basis. The trace of an element <span class="formula">x <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/> <img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span> was shown before to be <span class="formula"><img class="formulaInl" alt="$Tr(x) = \sum_{i=0}^{m-1}{x^{2^i}}$" src="form_1036_299.png" width="103" height="18"/></span>.Simultaneously, <span class="formula"><img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span> is a vector space <span class="formula">V</span> of dimension <span class="formula">m</span> over <span class="formulaF"> <img class="formulaInl" alt="$\mathbb{F}$" src="form_1036_6.png"/><sub>2</sub></span>. And the element <span class="formula">x</span> can be considered to be a linear transformation <span class="formula">x: V <img class="formulaInl" alt="$\rightarrow$" src="form_1036_67.png"/> V</span>, representing multiplication with <span class="formula">x</span>, carrying any element <span class="formula">y</span> to <span class="formula">xy</span>. Using the polynomial basis, let <span class="formula">T</span> be the matrix that carries any element <span class="formula">y</span> to <span class="formula">ty</span>. Thus, <span class="formula">Ty = ty</span> for any vector <span class="formula">y <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/> V</span> and where <span class="formula">t</span> is the special element as defined by the reduction map. Then <span class="formula">T</span> has the general form<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \begin{pmatrix} 0 &amp; 1 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; \ddots &amp; \vdots \\ 0 &amp; \vdots &amp; \vdots &amp; \ddots &amp; \ddots &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\ r_0 &amp; r_1 &amp; r_2 &amp; r_3 &amp; \cdots &amp; r_{m-1} \\ \end{pmatrix} \]" src="form_1036_300.png" width="171" height="106"/>
</p>
where the <span class="formula">r<sub>i</sub> <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/></span><span class="formulaF"> <img class="formulaInl" alt="$\mathbb{F}$" src="form_1036_6.png"/><sub>2</sub></span> are the coefficients of the reduction polynomial <span class="formula">r(t) = t<sup>m</sup> + r<sub>m-1</sub>t<sup>m-1</sup> + ... + r<sub>1</sub> t + r<sub>0</sub></span>. Note that always <span class="formula">r<sub>0</sub> = 1</span> or the reduction polynomial would not be irreducible.Also note that the trace of this matrix (the sum of the diagonal elements), and thus of <span class="formula">t</span>, equals <span class="formula">r<sub>m-1</sub></span> (a well-known fact, as is proven for example by <a href="http://www.bhargav.com/bhargav/schemes.pdf">Bhargav</a> (lemma 3.2)), <span class="formula">Tr(t) = r<sub>m-1</sub></span>.The characteristic polynomial of a linear transformation <span class="formula"><em>T</em></span> is defined as <span class="formula">f(e) = det(<em>T</em> - eI)</span>, where <span class="formula">I</span> is the identity matrix. Obviously it has coeficients in <span class="formulaF"> <img class="formulaInl" alt="$\mathbb{F}$" src="form_1036_6.png"/><sub>2</sub></span>, the ground field of <span class="formula">V</span>. The equation <span class="formula">f(e) = 0</span> has a solution if and only if <span class="formula">(<em>T</em> - eI)(v) = 0</span> for some nonzero vector <span class="formula">v</span>; in general, for any linear transformation A, det(A) = 0 if and only if Av = 0 is satisfied by a nonzero vector v. We are taking the special case of A = (<em>T</em> - eI). Now note that <span class="formula">(e, v)</span> is an eigenvalue&#160;-&#160;eigenvector pair of <span class="formula"><em>T</em></span> if and only if <span class="formula"><em>T</em>v = ev</span>, which is true if and only if <span class="formula">(<em>T</em> - eI)(v) = 0</span>. <span class="formula">e</span> is an eigenvalue of <span class="formula"><em>T</em></span> if and only if <span class="formula">f(e) = 0</span>, where <span class="formula">f</span> is the above mentioned characteristic polynomial.Now let <span class="formula">T</span> again be the matrix that carries an element <span class="formula">y</span> to <span class="formula">ty</span>. Then we will show that the characteristic polynomial of <span class="formula">T</span>, <span class="formula">f(e)</span>, is precisely the reduction polynomial <span class="formula">r</span> and thus <span class="formula">e</span> will be an eigenvalue of <span class="formula">T</span> if and only if <span class="formula">r(e) = 0</span>, and the eigenvalues of <span class="formula">T</span> turn out to be the roots of the reduction polynomial.The characteristic polynomial of <span class="formula">T</span> is <span class="formula">det(T - eI)</span> is<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \left| \begin{matrix} -e &amp; 1 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; -e &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; 0 &amp; -e &amp; 1 &amp; \ddots &amp; \vdots \\ 0 &amp; \vdots &amp; \vdots &amp; \ddots &amp; \ddots &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; -e &amp; 1 \\ r_0 &amp; r_1 &amp; r_2 &amp; r_3 &amp; \cdots &amp; r_{m-1} - e \end{matrix} \right| \]" src="form_1036_301.png" width="194" height="106"/>
</p>
It is easy to see that this determinant is the reduction polynomial because it is equal to<p class="formulaDsp">
<img class="formulaDsp" alt="\[ -e \left| \begin{matrix} -e &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; -e &amp; 1 &amp; \ddots &amp; \vdots \\ \vdots &amp; \vdots &amp; \ddots &amp; \ddots &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; -e &amp; 1 \\ r_1 &amp; r_2 &amp; r_3 &amp; \cdots &amp; r_{m-1} - e \end{matrix} \right| - 1 \cdot \left| \begin{matrix} 0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; -e &amp; 1 &amp; \ddots &amp; \vdots \\ \vdots &amp; \vdots &amp; \ddots &amp; \ddots &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; -e &amp; 1 \\ r_0 &amp; r_2 &amp; r_3 &amp; \cdots &amp; r_{m-1} - e \end{matrix} \right| \]" src="form_1036_302.png" width="380" height="91"/>
</p>
and the second underdeterminant can be worked out to<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \left| \begin{matrix} 0 &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; -e &amp; 1 &amp; \ddots &amp; \vdots \\ \vdots &amp; \vdots &amp; \ddots &amp; \ddots &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; -e &amp; 1 \\ r_0 &amp; r_2 &amp; r_3 &amp; \cdots &amp; r_{m-1} - e \end{matrix} \right| = -1 \cdot \left| \begin{matrix} 0 &amp; 1 &amp; \ddots &amp; \vdots \\ \vdots &amp; \ddots &amp; \ddots &amp; 0 \\ 0 &amp; 0 &amp; -e &amp; 1 \\ r_0 &amp; r_3 &amp; \cdots &amp; r_{m-1} - e \end{matrix} \right| = \cdots = (-1)^{m-3} \left| \begin{matrix} 0 &amp; 1 \\ r_0 &amp; r_{m-1} - e \end{matrix} \right| = (-1)^{m-2} r_0 \]" src="form_1036_303.png" width="590" height="91"/>
</p>
and thus<p class="formulaDsp">
<img class="formulaDsp" alt="\[ \left| \begin{matrix} -e &amp; 1 &amp; 0 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; -e &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; 0 &amp; -e &amp; 1 &amp; \ddots &amp; \vdots \\ 0 &amp; \vdots &amp; \vdots &amp; \ddots &amp; \ddots &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; -e &amp; 1 \\ r_0 &amp; r_1 &amp; r_2 &amp; r_3 &amp; \cdots &amp; r_{m-1} - e \end{matrix} \right| = -e \left| \begin{matrix} -e &amp; 1 &amp; 0 &amp; \cdots &amp; 0 \\ 0 &amp; -e &amp; 1 &amp; \ddots &amp; \vdots \\ \vdots &amp; \vdots &amp; \ddots &amp; \ddots &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; -e &amp; 1 \\ r_1 &amp; r_2 &amp; r_3 &amp; \cdots &amp; r_{m-1} - e \end{matrix} \right| + (-1)^{m-1} r_0 \]" src="form_1036_304.png" width="466" height="106"/>
</p>
then use this formula recursively to find that this is equal to<p class="formulaDsp">
<img class="formulaDsp" alt="\[ (-1)^2 e^2 \left| \begin{matrix} -e &amp; 1 &amp; \ddots &amp; \vdots \\ \vdots &amp; \ddots &amp; \ddots &amp; 0 \\ 0 &amp; 0 &amp; -e &amp; 1 \\ r_2 &amp; r_3 &amp; \cdots &amp; r_{m-1} - e \end{matrix} \right| -e (-1)^{m-2} r_1 + (-1)^{m-1} r_0 = \cdots = (-1)^{m-1} r(e) \]" src="form_1036_305.png" width="445" height="76"/>
</p>
Ok, almost equal then. However, in our case with characteristic 2, the <span class="formula">-1</span> is congruent <span class="formula">1</span> and in any case the equation <span class="formula">r(e) = 0</span> remains the equation that needs to be satisfied in order for <span class="formula">e</span> to be an eigenvalue of <span class="formula">T</span>.We already have one root of the characteristic polynomial of <span class="formula">T</span> therefore, because <span class="formula">r(t) = 0</span> by definition. As was shown before, the other roots of the reduction polynomial can be obtained by applying Frobenius <span class="formula">m - 1</span> times and we find that the eigenvalues of <span class="formula">T</span> are <span class="formula">e <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/> { t, t<sup>2</sup>, t<sup>4</sup>, ..., t<sup>2<sup>m-1</sup></sup> }</span>. Note that the eigenvector <span class="formula">v</span> that belongs to a given eigenvalue <span class="formula">e</span> is <span class="formula">(1 e e<sup>2</sup> e<sup>3</sup> ... e<sup>m-1</sup>)<sup>T</sup></span> (and any vector that can be obtained by multiplying this vector with a non-zero scalar of course; there will be <span class="formula">2<sup>m</sup> - 1</span> different vectors that satisfy <span class="formula">Tv = ev</span>).The trace of a linear transformation <span class="formula"><em>T</em></span> is known to be equal to the sum of the eigenvalues of <span class="formula"><em>T</em></span>. So, we find again that <span class="formula"><img class="formulaInl" alt="$Tr(t) = \sum_{i=0}^{m-1}{t^{2^i}}$" src="form_1036_306.png" width="98" height="18"/></span>. Note that the norm of <span class="formula"><em>T</em></span> (its determinant) is known to be equal to the product of the eigenvalues of <span class="formula"><em>T</em></span>. And thus we have <span class="formula"><span class="vbars">T</span> = <img class="formulaInl" alt="$\prod_{i=0}^{m-1}{t^{2^i}}$" src="form_1036_307.png" width="49" height="18"/> = t<sup>(2<sup>m</sup>-1)</sup> = 1</span>.Now we are ready to look new things.Consider the matrix <span class="formula">T<sup>n</sup></span>, then it is obvious that this matrix will have the exact same eigenvectors as <span class="formula">T</span>; for the eigenvalue-eigenvector pair <span class="formula">(e, v)</span> of <span class="formula">T</span> we find that <span class="formula">T<sup>n</sup> v = e<sup>n</sup> v</span> and thus <span class="formula">v</span> is an eigenvector of <span class="formula">T<sup>n</sup></span> with eigenvalue <span class="formula">e<sup>n</sup></span>.From this we can conclude that the trace of <span class="formula">t<sup>n</sup></span> equals the sum <span class="formula"><img class="formulaInl" alt="$Tr(t^n) = \sum_{i=0}^{m-1}{(t^{2^i})^n} = \sum_{i=0}^{m-1}{t^{2^in}} = \sum_{i=0}^{m-1}{(t^n)^{2^i}}$" src="form_1036_308.png" width="279" height="18"/></span>. Note that when <span class="formula">t</span> is a generator of the field so that any <span class="formula">x <img class="formulaInl" alt="$\in$" src="form_1036_4.png"/> <img class="formulaInl" alt="$\mathbb{F}_{2^m}$" src="form_1036_5.png"/></span> can be written as a power of <span class="formula">t</span>, then we arrive again at the general formula for the trace of a field element <span class="formula"><img class="formulaInl" alt="$Tr(x) = \sum_{i=0}^{m-1}{x^{2^i}}$" src="form_1036_299.png" width="103" height="18"/></span>. If the field is not primitive (<span class="formula">t</span> is not a generator), then we just have to find some generator <span class="formula">g</span> and use <span class="formula">(g, g<sup>2</sup>, g<sup>3</sup>, ..., g<sup>m-1</sup>)</span> as basis and will get the same result. And while we're at it, also note that <span class="formula"><span class="vbars">T<sup>n</sup></span> = <img class="formulaInl" alt="$\prod_{i=0}^{m-1}{(g^{2^i})^n}$" src="form_1036_309.png" width="68" height="18"/> = <span class="vbars">T</span><sup>n</sup> = 1</span>.We found above that the eigenvalues of <span class="formula">T</span> are precisely the roots of the reduction polynomial. That means that we can write the reduction polynomial as<span class="formulaDsp"> <span class="formula">r(t) = (t - e<sub>1</sub>)(t - e<sub>2</sub>) <img class="formulaInl" alt="$\cdots$" src="form_1036_88.png"/> (t - e<sub>m</sub>)</span></span>Where the <span class="formula">e<sub>i</sub></span>, the <span class="formula">m</span> eigenvalues of <span class="formula">T</span>, are the zeros. Expanding and using induction, we see that<span class="formulaDsp"> <span class="formula">r(t) = t<sup>m</sup> - S<sub>1</sub>t<sup>m-1</sup> + S<sub>2</sub>t<sup>m-2</sup> + <img class="formulaInl" alt="$\cdots$" src="form_1036_88.png"/> + (-1)<sup>m</sup>S<sub>m</sub></span></span>Or, since we have characteristic 2,<span class="formulaDsp"> <span class="formula">r(t) = t<sup>m</sup> + S<sub>1</sub>t<sup>m-1</sup> + S<sub>2</sub>t<sup>m-2</sup> + <img class="formulaInl" alt="$\cdots$" src="form_1036_88.png"/> + S<sub>m</sub></span></span>where the S<sub>i</sub> are the <a class="el" href="group__theory__sympoly.html#elementarysympoly">Elementary Symmetric Polynomials</a> of the <span class="formula">m</span> variables <span class="formula">e<sub>1</sub></span>, <span class="formula">e<sub>2</sub></span>, ..., <span class="formula">e<sub>m</sub></span>.Moreover, using the fact that <span class="formula"><img class="formulaInl" alt="$Tr(t^n) = \sum_{i=0}^{m-1}{(t^{2^i})^n}$" src="form_1036_310.png" width="121" height="18"/></span>, we can write<span class="formulaDsp"> <span class="formula">Tr(t<sup>n</sup>) = N<sub>n</sub></span></span>where the N<sub>n</sub> are the <a class="el" href="group__theory__sympoly.html#newtonsympoly">Newton Symmetric Polynomials</a> of the <span class="formula">m</span> variables <span class="formula">e<sub>1</sub></span>, <span class="formula">e<sub>2</sub></span>, ..., <span class="formula">e<sub>m</sub></span>.If we restrict ourselfs to reduction polynomials of the form <span class="formula">t<sup>m</sup> + t<sup>k<sub>0</sub></sup> + t<sup>k<sub>1</sub></sup> + <img class="formulaInl" alt="$\cdots$" src="form_1036_88.png"/> + t<sup>k<sub>n</sub></sup> + 1</span>, where each <span class="formula">k<sub>i</sub> <img class="formulaInl" alt="$\le$" src="form_1036_153.png" width="9" height="11"/> m / 2</span>, then the first <span class="formula">floor((m - 1) / 2)</span> ESP's are zero.Using the fact that the characteristic of the field is 2, the <a class="el" href="group__theory__sympoly.html#newtonrelation">relationship</a> between NSP's and ESP's becomes<p class="formulaDsp">
<img class="formulaDsp" alt="\[ N_n = nS_n + \sum_{i=1}^{n-1} S_iN_{n-i} \]" src="form_1036_311.png" width="131" height="38"/>
</p>
From this we see immediately that, since <span class="formula">S<sub>i</sub> = 0</span> for all <span class="formula">i <img class="formulaInl" alt="$\le$" src="form_1036_153.png" width="9" height="11"/> floor((m - 1) / 2)</span>, also <span class="formula">N<sub>i</sub> = 0</span> for all <span class="formula">i <img class="formulaInl" alt="$\le$" src="form_1036_153.png" width="9" height="11"/> floor((m - 1) / 2)</span>. Whence the sum <img class="formulaInl" alt="$\sum_{i=1}^{n-1} S_iN_{n-i}$" src="form_1036_312.png" width="74" height="16"/> is zero for any value <span class="formula">n &lt; m</span>.For example, when <span class="formula">m = 6</span> (even <span class="formula">m</span> is most critical) then only the first two ESP's and NSP's are garanteed zero: <span class="formula">S<sub>1</sub> = S<sub>2</sub> = N<sub>1</sub> = N<sub>2</sub> = 0</span>. And the sum exists of a maximum number of terms when <span class="formula">n</span> is maximum, <span class="formula">n = m - 1 = 5</span>, resulting in the sum <span class="formula"><img class="formulaInl" alt="$\sum_{i=1}^{n-1} S_iN_{n-i}$" src="form_1036_312.png" width="74" height="16"/> = S<sub>1</sub>N<sub>4</sub> + S<sub>2</sub>N<sub>3</sub> + S<sub>3</sub>N<sub>2</sub> + S<sub>4</sub>N<sub>1</sub> = 0</span>.In other words, again remembering that the characteristic is 2, we find that for any <span class="formula">0 &lt; n &lt; m</span><p class="formulaDsp">
<img class="formulaDsp" alt="\[ Tr(t^n) = N_n = \begin{cases} 0 &amp; \text{ n is even } \\ S_n &amp; \text{ n is odd } \end{cases} \]" src="form_1036_313.png" width="176" height="39"/>
</p>
This doesn't cover <span class="formula">n = 0</span>, but we already know that <span class="formula">Tr(1) = 1</span> iff <span class="formula">m</span> is odd.QED </div></div><!-- contents -->
<address>Copyright &copy; 2002-2008 Carlo Wood.&nbsp; All rights reserved.</address>
</div>
</body>
</html>
